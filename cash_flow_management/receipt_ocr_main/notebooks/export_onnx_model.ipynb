{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enormous-reward",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import onnx\n",
    "import torch\n",
    "import torch.onnx\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.model import DefaultModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stock-christian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-slope",
   "metadata": {},
   "source": [
    "## Load model network and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coastal-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_cfg = '../configs/craft_config.yaml'\n",
    "detector_model = '../models/text_detector/craft_mlt_25k.pth'\n",
    "recognizer_cfg = '../configs/star_config.yaml'\n",
    "recognizer_model = '../models/text_recognizer/TPS-ResNet-BiLSTM-Attn-case-sensitive.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "brief-victor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights from checkpoint (../models/text_detector/craft_mlt_25k.pth)\n",
      "Loading weights from checkpoint (../models/text_recognizer/TPS-ResNet-BiLSTM-Attn-case-sensitive.pth)\n"
     ]
    }
   ],
   "source": [
    "model = DefaultModel(detector_cfg, detector_model, \n",
    "                     recognizer_cfg, recognizer_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-fence",
   "metadata": {},
   "source": [
    "# Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-enforcement",
   "metadata": {},
   "source": [
    "## Exporter Model\n",
    "Batch Size X Channel X Height X Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lasting-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_dummy_input = torch.randn(1, 3, 1280, 720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "expanded-enzyme",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.0010, 0.0002],\n",
       "           [0.0085, 0.0020],\n",
       "           [0.0010, 0.0002],\n",
       "           ...,\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0019, 0.0016],\n",
       "           [0.0010, 0.0002]],\n",
       " \n",
       "          [[0.0022, 0.0016],\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002],\n",
       "           ...,\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002]],\n",
       " \n",
       "          [[0.0010, 0.0002],\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002],\n",
       "           ...,\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0010, 0.0002],\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002],\n",
       "           ...,\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002]],\n",
       " \n",
       "          [[0.0128, 0.0013],\n",
       "           [0.0056, 0.0013],\n",
       "           [0.0065, 0.0015],\n",
       "           ...,\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0010, 0.0002],\n",
       "           [0.0020, 0.0006]],\n",
       " \n",
       "          [[0.0065, 0.0086],\n",
       "           [0.0084, 0.0021],\n",
       "           [0.0093, 0.0018],\n",
       "           ...,\n",
       "           [0.0037, 0.0011],\n",
       "           [0.0024, 0.0007],\n",
       "           [0.0100, 0.0079]]]], grad_fn=<PermuteBackward>),\n",
       " tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0552],\n",
       "           [0.0870, 0.0165, 0.2143,  ..., 0.0000, 0.0000, 0.0886],\n",
       "           [0.0047, 0.0641, 0.2276,  ..., 0.0000, 0.0000, 0.0913],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.2815,  ..., 1.2193, 1.1758, 1.3355],\n",
       "           [0.0000, 0.0000, 0.4303,  ..., 1.3450, 1.2745, 1.4509],\n",
       "           [0.0000, 0.0000, 0.2416,  ..., 0.8716, 0.9751, 1.0762]],\n",
       " \n",
       "          [[0.1752, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3734],\n",
       "           [0.1021, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0797],\n",
       "           [0.1667, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0534],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0576, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1832]],\n",
       " \n",
       "          [[1.0205, 0.6065, 0.8373,  ..., 0.2779, 0.2694, 0.6539],\n",
       "           [0.9442, 0.3013, 0.7273,  ..., 0.6779, 0.8180, 1.2405],\n",
       "           [1.3239, 0.6361, 0.8955,  ..., 0.7086, 0.7718, 1.0392],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.2606, 2.2630],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.4381, 0.4628, 1.9584],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.2608, 0.3710, 1.2387]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0000, 0.0000, 0.0221,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.2290, 0.2829,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0408, 0.0449,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.7339, 1.3421, 1.8549,  ..., 2.7119, 2.3538, 1.3433],\n",
       "           [0.2865, 0.6955, 0.9729,  ..., 1.9042, 1.6367, 1.0503],\n",
       "           [0.3265, 0.5312, 0.6013,  ..., 1.1321, 0.9693, 0.7332]],\n",
       " \n",
       "          [[0.3608, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0601, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0870, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       " \n",
       "          [[0.0937, 0.1586, 0.0410,  ..., 0.1801, 0.1988, 0.4503],\n",
       "           [0.0000, 0.0638, 0.1298,  ..., 0.0000, 0.0304, 0.4700],\n",
       "           [0.0000, 0.1438, 0.1875,  ..., 0.0000, 0.1855, 0.5608],\n",
       "           ...,\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "           [0.0997, 0.0000, 0.0000,  ..., 0.0000, 0.2321, 0.6662]]]],\n",
       "        grad_fn=<ReluBackward1>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.detector(detector_dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "devoted-information",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_detector_model = '../models/text_detector/craft.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "arbitrary-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the model\n",
    "torch.onnx.export(model.detector,            \n",
    "                  detector_dummy_input,\n",
    "                  out_detector_model,\n",
    "                  export_params=True,\n",
    "                  opset_version=13,\n",
    "                  do_constant_folding=True,\n",
    "                  input_names = ['input'],\n",
    "                  output_names = ['output'],\n",
    "                  dynamic_axes={'input' : {0:'batch_size', 2:'height', 3:'width'},\n",
    "                                'output' : {0:'batch_size'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-librarian",
   "metadata": {},
   "source": [
    "## Inspecting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cognitive-albania",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %input[FLOAT, batch_sizex3xheightxwidth]\n",
      ") initializers (\n",
      "  %basenet.slice5.1.weight[FLOAT, 1024x512x3x3]\n",
      "  %basenet.slice5.1.bias[FLOAT, 1024]\n",
      "  %basenet.slice5.2.weight[FLOAT, 1024x1024x1x1]\n",
      "  %basenet.slice5.2.bias[FLOAT, 1024]\n",
      "  %conv_cls.0.weight[FLOAT, 32x32x3x3]\n",
      "  %conv_cls.0.bias[FLOAT, 32]\n",
      "  %conv_cls.2.weight[FLOAT, 32x32x3x3]\n",
      "  %conv_cls.2.bias[FLOAT, 32]\n",
      "  %conv_cls.4.weight[FLOAT, 16x32x3x3]\n",
      "  %conv_cls.4.bias[FLOAT, 16]\n",
      "  %conv_cls.6.weight[FLOAT, 16x16x1x1]\n",
      "  %conv_cls.6.bias[FLOAT, 16]\n",
      "  %conv_cls.8.weight[FLOAT, 2x16x1x1]\n",
      "  %conv_cls.8.bias[FLOAT, 2]\n",
      "  %299[FLOAT, 64x3x3x3]\n",
      "  %300[FLOAT, 64]\n",
      "  %302[FLOAT, 64x64x3x3]\n",
      "  %303[FLOAT, 64]\n",
      "  %305[FLOAT, 128x64x3x3]\n",
      "  %306[FLOAT, 128]\n",
      "  %308[FLOAT, 128x128x3x3]\n",
      "  %309[FLOAT, 128]\n",
      "  %311[FLOAT, 256x128x3x3]\n",
      "  %312[FLOAT, 256]\n",
      "  %314[FLOAT, 256x256x3x3]\n",
      "  %315[FLOAT, 256]\n",
      "  %317[FLOAT, 256x256x3x3]\n",
      "  %318[FLOAT, 256]\n",
      "  %320[FLOAT, 512x256x3x3]\n",
      "  %321[FLOAT, 512]\n",
      "  %323[FLOAT, 512x512x3x3]\n",
      "  %324[FLOAT, 512]\n",
      "  %326[FLOAT, 512x512x3x3]\n",
      "  %327[FLOAT, 512]\n",
      "  %329[FLOAT, 512x512x3x3]\n",
      "  %330[FLOAT, 512]\n",
      "  %332[FLOAT, 512x512x3x3]\n",
      "  %333[FLOAT, 512]\n",
      "  %335[FLOAT, 512x1536x1x1]\n",
      "  %336[FLOAT, 512]\n",
      "  %338[FLOAT, 256x512x3x3]\n",
      "  %339[FLOAT, 256]\n",
      "  %341[FLOAT, 256x768x1x1]\n",
      "  %342[FLOAT, 256]\n",
      "  %344[FLOAT, 128x256x3x3]\n",
      "  %345[FLOAT, 128]\n",
      "  %347[FLOAT, 128x384x1x1]\n",
      "  %348[FLOAT, 128]\n",
      "  %350[FLOAT, 64x128x3x3]\n",
      "  %351[FLOAT, 64]\n",
      "  %353[FLOAT, 64x192x1x1]\n",
      "  %354[FLOAT, 64]\n",
      "  %356[FLOAT, 32x64x3x3]\n",
      "  %357[FLOAT, 32]\n",
      ") {\n",
      "  %298 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%input, %299, %300)\n",
      "  %157 = Relu(%298)\n",
      "  %301 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%157, %302, %303)\n",
      "  %160 = Relu(%301)\n",
      "  %161 = MaxPool[ceil_mode = 0, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%160)\n",
      "  %304 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%161, %305, %306)\n",
      "  %164 = Relu(%304)\n",
      "  %307 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%164, %308, %309)\n",
      "  %167 = Relu(%307)\n",
      "  %168 = MaxPool[ceil_mode = 0, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%167)\n",
      "  %310 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%168, %311, %312)\n",
      "  %171 = Relu(%310)\n",
      "  %313 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%171, %314, %315)\n",
      "  %174 = Relu(%313)\n",
      "  %316 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%174, %317, %318)\n",
      "  %177 = Relu(%316)\n",
      "  %178 = MaxPool[ceil_mode = 0, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%177)\n",
      "  %319 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%178, %320, %321)\n",
      "  %181 = Relu(%319)\n",
      "  %322 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%181, %323, %324)\n",
      "  %184 = Relu(%322)\n",
      "  %325 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%184, %326, %327)\n",
      "  %187 = Relu(%325)\n",
      "  %188 = MaxPool[ceil_mode = 0, kernel_shape = [2, 2], pads = [0, 0, 0, 0], strides = [2, 2]](%187)\n",
      "  %328 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%188, %329, %330)\n",
      "  %191 = Relu(%328)\n",
      "  %331 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%191, %332, %333)\n",
      "  %194 = MaxPool[ceil_mode = 0, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%331)\n",
      "  %195 = Conv[dilations = [6, 6], group = 1, kernel_shape = [3, 3], pads = [6, 6, 6, 6], strides = [1, 1]](%194, %basenet.slice5.1.weight, %basenet.slice5.1.bias)\n",
      "  %196 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%195, %basenet.slice5.2.weight, %basenet.slice5.2.bias)\n",
      "  %197 = Concat[axis = 1](%196, %331)\n",
      "  %334 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%197, %335, %336)\n",
      "  %200 = Relu(%334)\n",
      "  %337 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%200, %338, %339)\n",
      "  %203 = Relu(%337)\n",
      "  %204 = Shape(%184)\n",
      "  %205 = Constant[value = <Scalar Tensor []>]()\n",
      "  %206 = Gather[axis = 0](%204, %205)\n",
      "  %207 = Shape(%184)\n",
      "  %208 = Constant[value = <Scalar Tensor []>]()\n",
      "  %209 = Gather[axis = 0](%207, %208)\n",
      "  %210 = Constant[value = <Tensor>]()\n",
      "  %211 = Unsqueeze(%206, %210)\n",
      "  %212 = Constant[value = <Tensor>]()\n",
      "  %213 = Unsqueeze(%209, %212)\n",
      "  %214 = Concat[axis = 0](%211, %213)\n",
      "  %215 = Shape(%203)\n",
      "  %216 = Constant[value = <Tensor>]()\n",
      "  %217 = Constant[value = <Tensor>]()\n",
      "  %218 = Constant[value = <Tensor>]()\n",
      "  %219 = Slice(%215, %217, %218, %216)\n",
      "  %220 = Cast[to = 7](%214)\n",
      "  %221 = Concat[axis = 0](%219, %220)\n",
      "  %224 = Resize[coordinate_transformation_mode = 'pytorch_half_pixel', cubic_coeff_a = -0.75, mode = 'linear', nearest_mode = 'floor'](%203, %, %, %221)\n",
      "  %225 = Concat[axis = 1](%224, %184)\n",
      "  %340 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%225, %341, %342)\n",
      "  %228 = Relu(%340)\n",
      "  %343 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%228, %344, %345)\n",
      "  %231 = Relu(%343)\n",
      "  %232 = Shape(%174)\n",
      "  %233 = Constant[value = <Scalar Tensor []>]()\n",
      "  %234 = Gather[axis = 0](%232, %233)\n",
      "  %235 = Shape(%174)\n",
      "  %236 = Constant[value = <Scalar Tensor []>]()\n",
      "  %237 = Gather[axis = 0](%235, %236)\n",
      "  %238 = Constant[value = <Tensor>]()\n",
      "  %239 = Unsqueeze(%234, %238)\n",
      "  %240 = Constant[value = <Tensor>]()\n",
      "  %241 = Unsqueeze(%237, %240)\n",
      "  %242 = Concat[axis = 0](%239, %241)\n",
      "  %243 = Shape(%231)\n",
      "  %244 = Constant[value = <Tensor>]()\n",
      "  %245 = Constant[value = <Tensor>]()\n",
      "  %246 = Constant[value = <Tensor>]()\n",
      "  %247 = Slice(%243, %245, %246, %244)\n",
      "  %248 = Cast[to = 7](%242)\n",
      "  %249 = Concat[axis = 0](%247, %248)\n",
      "  %252 = Resize[coordinate_transformation_mode = 'pytorch_half_pixel', cubic_coeff_a = -0.75, mode = 'linear', nearest_mode = 'floor'](%231, %, %, %249)\n",
      "  %253 = Concat[axis = 1](%252, %174)\n",
      "  %346 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%253, %347, %348)\n",
      "  %256 = Relu(%346)\n",
      "  %349 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%256, %350, %351)\n",
      "  %259 = Relu(%349)\n",
      "  %260 = Shape(%167)\n",
      "  %261 = Constant[value = <Scalar Tensor []>]()\n",
      "  %262 = Gather[axis = 0](%260, %261)\n",
      "  %263 = Shape(%167)\n",
      "  %264 = Constant[value = <Scalar Tensor []>]()\n",
      "  %265 = Gather[axis = 0](%263, %264)\n",
      "  %266 = Constant[value = <Tensor>]()\n",
      "  %267 = Unsqueeze(%262, %266)\n",
      "  %268 = Constant[value = <Tensor>]()\n",
      "  %269 = Unsqueeze(%265, %268)\n",
      "  %270 = Concat[axis = 0](%267, %269)\n",
      "  %271 = Shape(%259)\n",
      "  %272 = Constant[value = <Tensor>]()\n",
      "  %273 = Constant[value = <Tensor>]()\n",
      "  %274 = Constant[value = <Tensor>]()\n",
      "  %275 = Slice(%271, %273, %274, %272)\n",
      "  %276 = Cast[to = 7](%270)\n",
      "  %277 = Concat[axis = 0](%275, %276)\n",
      "  %280 = Resize[coordinate_transformation_mode = 'pytorch_half_pixel', cubic_coeff_a = -0.75, mode = 'linear', nearest_mode = 'floor'](%259, %, %, %277)\n",
      "  %281 = Concat[axis = 1](%280, %167)\n",
      "  %352 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%281, %353, %354)\n",
      "  %284 = Relu(%352)\n",
      "  %355 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%284, %356, %357)\n",
      "  %287 = Relu(%355)\n",
      "  %288 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%287, %conv_cls.0.weight, %conv_cls.0.bias)\n",
      "  %289 = Relu(%288)\n",
      "  %290 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%289, %conv_cls.2.weight, %conv_cls.2.bias)\n",
      "  %291 = Relu(%290)\n",
      "  %292 = Conv[dilations = [1, 1], group = 1, kernel_shape = [3, 3], pads = [1, 1, 1, 1], strides = [1, 1]](%291, %conv_cls.4.weight, %conv_cls.4.bias)\n",
      "  %293 = Relu(%292)\n",
      "  %294 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%293, %conv_cls.6.weight, %conv_cls.6.bias)\n",
      "  %295 = Relu(%294)\n",
      "  %296 = Conv[dilations = [1, 1], group = 1, kernel_shape = [1, 1], pads = [0, 0, 0, 0], strides = [1, 1]](%295, %conv_cls.8.weight, %conv_cls.8.bias)\n",
      "  %output = Transpose[perm = [0, 2, 3, 1]](%296)\n",
      "  return %output, %287\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(out_detector_model)\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-northwest",
   "metadata": {},
   "source": [
    "# Recognizer\n",
    "\n",
    "ERROR UNSOLVED BY CREATOR\n",
    "https://github.com/pytorch/pytorch/issues/27212"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-institution",
   "metadata": {},
   "source": [
    "## Exporter Model\n",
    "Batch Size X Channel X Height X Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "italian-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer_dummy_input = torch.randn(100, 1, 32, 100)\n",
    "recognizer_dummy_text = torch.LongTensor(100, 26).fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sized-truck",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ -6.9061,  -7.5613,  -5.4793,  ...,  -2.4262,  -4.9112,  -4.1666],\n",
       "         [-11.9275, -13.6367, -11.6911,  ..., -10.5464, -11.6802, -11.4881],\n",
       "         [-15.8177, -16.6920, -15.7986,  ..., -15.0340, -15.5713, -15.5707],\n",
       "         ...,\n",
       "         [-13.8261,  -2.1892, -13.1530,  ..., -13.9286, -13.0425, -13.7967],\n",
       "         [-13.8304,  -2.1870, -13.1481,  ..., -13.9520, -13.0352, -13.8002],\n",
       "         [-13.8197,  -2.1547, -13.1142,  ..., -13.9470, -13.0154, -13.7876]],\n",
       "\n",
       "        [[ -8.2746,  -8.6355,  -6.8791,  ...,  -6.2013,  -8.2145,  -6.9954],\n",
       "         [-13.3459, -18.1712, -12.9131,  ..., -12.4395, -12.8243, -11.7817],\n",
       "         [-15.9471, -18.3970, -13.9544,  ..., -14.9989, -15.8966, -14.6564],\n",
       "         ...,\n",
       "         [-13.8625,  -3.7098, -11.3744,  ..., -13.9167, -12.4986, -14.3229],\n",
       "         [-13.8717,  -3.6356, -11.3872,  ..., -13.9434, -12.5487, -14.3171],\n",
       "         [-13.8459,  -3.6648, -11.3504,  ..., -13.9306, -12.5294, -14.2871]],\n",
       "\n",
       "        [[ -9.2234,  -8.9115,  -7.3134,  ...,  -8.0188,  -9.4038,  -7.2299],\n",
       "         [-14.8482, -16.4109, -13.4717,  ..., -14.9134, -15.2613, -14.8936],\n",
       "         [-18.2801, -17.6252, -17.8121,  ..., -17.7865, -18.4960, -17.5789],\n",
       "         ...,\n",
       "         [-14.0301,  -4.4127, -15.5972,  ..., -13.7900, -13.4122, -14.4714],\n",
       "         [-14.0370,  -4.2523, -15.5777,  ..., -13.7668, -13.4058, -14.4595],\n",
       "         [-14.0503,  -4.2084, -15.6115,  ..., -13.8018, -13.4401, -14.5031]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ -7.1346,  -8.7684,  -3.9511,  ...,  -6.0389,  -7.8837,  -6.5712],\n",
       "         [-13.3955, -14.4589, -13.1261,  ..., -12.2595, -12.9576, -12.9921],\n",
       "         [-16.3747, -14.4627, -16.1623,  ..., -15.8627, -17.5044, -15.9218],\n",
       "         ...,\n",
       "         [-12.4704,  -3.2038, -12.0584,  ..., -13.4266, -12.3316, -12.8561],\n",
       "         [-12.4187,  -3.2129, -11.9786,  ..., -13.3757, -12.2918, -12.8280],\n",
       "         [-12.3670,  -3.2296, -11.9009,  ..., -13.3300, -12.2517, -12.7935]],\n",
       "\n",
       "        [[ -8.4369,  -8.5261,  -6.7348,  ...,  -7.9101,  -9.0706,  -8.3969],\n",
       "         [-13.5088, -12.4055, -13.0897,  ..., -12.9229, -13.2860, -13.7020],\n",
       "         [-15.6351, -13.3638, -15.9259,  ..., -15.3991, -15.9885, -16.2208],\n",
       "         ...,\n",
       "         [-11.8698,  -4.2842, -11.2330,  ..., -13.6111, -12.6553, -13.3193],\n",
       "         [-11.8772,  -4.2873, -11.2386,  ..., -13.6150, -12.6616, -13.3284],\n",
       "         [-11.8831,  -4.3029, -11.2439,  ..., -13.6189, -12.6683, -13.3351]],\n",
       "\n",
       "        [[ -5.7706,  -4.6843,  -6.4071,  ...,  -3.7921,  -4.4570,  -4.4655],\n",
       "         [-12.4181, -13.1821, -10.1006,  ...,  -9.4514, -11.3294, -11.0276],\n",
       "         [-13.5660, -13.7678,  -9.6513,  ..., -13.9703, -14.8214, -13.9399],\n",
       "         ...,\n",
       "         [-13.8621,  -3.4651, -13.2679,  ..., -14.5769, -13.8149, -14.4902],\n",
       "         [-13.8660,  -3.4625, -13.2367,  ..., -14.5793, -13.8194, -14.4901],\n",
       "         [-13.8639,  -3.4490, -13.2186,  ..., -14.5810, -13.8137, -14.4848]]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.recognizer.module(recognizer_dummy_input, recognizer_dummy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "enabling-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_recognizer_model = '../models/text_recognizer/star.onnx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "roman-medicare",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Exporting the operator grid_sampler to ONNX opset version 13 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17483/4145972323.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Export the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m torch.onnx.export(model.recognizer.module,            \n\u001b[0m\u001b[1;32m      3\u001b[0m                   \u001b[0;34m(\u001b[0m\u001b[0mrecognizer_dummy_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecognizer_dummy_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0mout_recognizer_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                   \u001b[0mexport_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/receipt-ocr/lib/python3.9/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     return utils.export(model, args, f, export_params, verbose, training,\n\u001b[0m\u001b[1;32m    276\u001b[0m                         \u001b[0minput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_raw_ir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0moperator_export_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/receipt-ocr/lib/python3.9/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36mexport\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, example_outputs, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, custom_opsets, enable_onnx_checker, use_external_data_format)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0moperator_export_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOperatorExportTypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     _export(model, args, f, export_params, verbose, training, input_names, output_names,\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0moperator_export_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator_export_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopset_version\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdo_constant_folding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/receipt-ocr/lib/python3.9/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, opset_version, _retain_param_name, do_constant_folding, strip_doc_string, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, enable_onnx_checker, use_external_data_format, onnx_shape_inference)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_out\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 _model_to_graph(model, args, verbose, input_names,\n\u001b[0m\u001b[1;32m    690\u001b[0m                                 \u001b[0moutput_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                                 \u001b[0mexample_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_retain_param_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/receipt-ocr/lib/python3.9/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_model_to_graph\u001b[0;34m(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, _retain_param_name, do_constant_folding, _disable_torch_constant_prop, fixed_batch_size, training, dynamic_axes)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mparams_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_named_param_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     graph = _optimize_graph(graph, operator_export_type,\n\u001b[0m\u001b[1;32m    464\u001b[0m                             \u001b[0m_disable_torch_constant_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_disable_torch_constant_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                             \u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/receipt-ocr/lib/python3.9/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_optimize_graph\u001b[0;34m(graph, operator_export_type, _disable_torch_constant_prop, fixed_batch_size, params_dict, dynamic_axes, input_names, module)\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mdynamic_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdynamic_axes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx_set_dynamic_input_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_onnx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_lint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/receipt-ocr/lib/python3.9/site-packages/torch/onnx/__init__.py\u001b[0m in \u001b[0;36m_run_symbolic_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_run_symbolic_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_symbolic_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/receipt-ocr/lib/python3.9/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_run_symbolic_function\u001b[0;34m(g, block, n, inputs, env, operator_export_type)\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;31m# Export it regularly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m                 \u001b[0mdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                 \u001b[0msymbolic_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_symbolic_in_registry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msymbolic_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/receipt-ocr/lib/python3.9/site-packages/torch/onnx/utils.py\u001b[0m in \u001b[0;36m_find_symbolic_in_registry\u001b[0;34m(domain, op_name, opset_version, operator_export_type)\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0;31m# Use the original node directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msym_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_registered_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/receipt-ocr/lib/python3.9/site-packages/torch/onnx/symbolic_registry.py\u001b[0m in \u001b[0;36mget_registered_op\u001b[0;34m(opname, domain, version)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please feel free to request support or submit a pull request on PyTorch GitHub.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_registry\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Exporting the operator grid_sampler to ONNX opset version 13 is not supported. Please feel free to request support or submit a pull request on PyTorch GitHub."
     ]
    }
   ],
   "source": [
    "# Export the model\n",
    "torch.onnx.export(model.recognizer.module,            \n",
    "                  (recognizer_dummy_input, recognizer_dummy_text),\n",
    "                  out_recognizer_model,\n",
    "                  export_params=True,\n",
    "                  opset_version=13,\n",
    "                  do_constant_folding=True,\n",
    "                  input_names = ['input'],\n",
    "                  output_names = ['output'],\n",
    "                  dynamic_axes={'input' : {0:'batch_size', 2:'height', 3:'width'},\n",
    "                                'output' : {0:'batch_size'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-grill",
   "metadata": {},
   "source": [
    "## Inspecting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(out_recognizer_model)\n",
    "\n",
    "# Check that the IR is well formed\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:receipt-ocr]",
   "language": "python",
   "name": "conda-env-receipt-ocr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
